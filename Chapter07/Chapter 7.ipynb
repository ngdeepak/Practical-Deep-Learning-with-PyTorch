{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ff5c82-8900-462c-bb30-e56b6b96fa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to sequence: [8, 5, 12, 12, 15]\n",
      "Sequence to text: hello\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the character set and the mapping from index to character\n",
    "char_list = [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "             'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '<blank>']\n",
    "idx2char = {idx: char for idx, char in enumerate(char_list)}\n",
    "char2idx = {char: idx for idx, char in enumerate(char_list)}\n",
    "\n",
    "def text_to_int_sequence(text):\n",
    "    \"\"\"Converts text to an integer sequence.\"\"\"\n",
    "    return [char2idx[char] for char in text]\n",
    "\n",
    "def int_sequence_to_text(sequence):\n",
    "    \"\"\"Converts an integer sequence to text.\"\"\"\n",
    "    return ''.join(idx2char[idx] for idx in sequence if idx != char2idx['<blank>'])\n",
    "\n",
    "# Example usage:\n",
    "text = \"hello\"\n",
    "sequence = text_to_int_sequence(text)\n",
    "print(\"Text to sequence:\", sequence)\n",
    "print(\"Sequence to text:\", int_sequence_to_text(sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0f78ee-5682-42cf-aaa5-6b35de83a215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'<pad>': 0, '<unk>': 1, 'hello': 2, 'world': 3, 'how': 4, 'are': 5, 'you': 6, 'doing?': 7, 'this': 8, 'is': 9, 'a': 10, 'test': 11, 'text': 12, 'for': 13, 'speech-to-textstt.': 14}\n",
      "Sequence: [4, 5, 6, 7]\n",
      "Tensor shape: torch.Size([3, 7])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    " \n",
    "def tokenize_text(text):\n",
    "    \"\"\" Tokenizes text into a list of words. \"\"\"\n",
    "    return text.lower().strip().split()\n",
    " \n",
    "def build_vocab(texts):\n",
    "    \"\"\" Builds a vocabulary from a list of texts. \"\"\"\n",
    "    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "    idx = 2\n",
    "    for text in texts:\n",
    "        tokens = tokenize_text(text)\n",
    "        for token in tokens:\n",
    "            if token not in vocab:\n",
    "                vocab[token] = idx\n",
    "                idx += 1\n",
    "    return vocab\n",
    " \n",
    "# Example text data\n",
    "texts = [\"Hello world\", \"How are you doing?\", \"This is a test text for speech-to-textSTT.\"]\n",
    " \n",
    "# Build vocabulary\n",
    "vocab = build_vocab(texts)\n",
    "print(\"Vocabulary:\", vocab)\n",
    " \n",
    "def text_to_sequence(text, vocab):\n",
    "    \"\"\" Converts text to a sequence of indices. \"\"\"\n",
    "    tokens = tokenize_text(text)\n",
    "    return [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n",
    " \n",
    "# Convert a sample text to sequence\n",
    "sample_text = \"How are you doing?\"\n",
    "sequence = text_to_sequence(sample_text, vocab)\n",
    "print(\"Sequence:\", sequence)\n",
    " \n",
    "def sequence_to_tensor(sequence):\n",
    "    \"\"\" Converts a list of sequences into a tensor, padded to the same length. \"\"\"\n",
    "    max_len = max(len(s) for s in sequence)\n",
    "    padded = [s + [vocab[\"<pad>\"]] * (max_len - len(s)) for s in sequence]\n",
    "    return torch.tensor(padded)\n",
    " \n",
    "# Convert sequences to tensor\n",
    "sequences = [text_to_sequence(text, vocab) for text in texts]\n",
    "tensor = sequence_to_tensor(sequences)\n",
    "print(\"Tensor shape:\", tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4f03c-f29f-4cfe-b0cb-e05b0806bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_sequence(sequences, batch_first=False, padding_value=0):\n",
    "    \"\"\"Pad sequences to the same length with the given padding value.\"\"\"\n",
    "    max_size = sequences[0].size()\n",
    "    trailing_dims = max_size[1:]\n",
    "    max_len = max([s.size(0) for s in sequences])\n",
    "    if batch_first:\n",
    "        out_dims = (len(sequences), max_len) + trailing_dims\n",
    "    else:\n",
    "        out_dims = (max_len, len(sequences)) + trailing_dims\n",
    " \n",
    "    out_tensor = sequences[0].data.new_full(out_dims, padding_value)\n",
    "    for i, tensor in enumerate(sequences):\n",
    "        length = tensor.size(0)\n",
    "        if batch_first:\n",
    "            out_tensor[i, :length, ...] = tensor\n",
    "        else:\n",
    "            out_tensor[:length, i, ...] = tensor\n",
    " \n",
    "    return out_tensor\n",
    " \n",
    "# Example: Padding text data for a batch\n",
    "batch_texts = [\"hello\", \"data\", \"world\"]\n",
    "batch_encoded = [torch.tensor(text_processor.text_to_int(text)) for text in batch_texts]\n",
    "padded_texts = pad_sequence(batch_encoded, batch_first=True, padding_value=text_processor.char2index['<pad>'])\n",
    " \n",
    "print(\"Padded Text Batch:\", padded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab450f0-7da7-4d9a-b7de-6176813bf72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Text: how are you doing?\n"
     ]
    }
   ],
   "source": [
    "def sequence_to_text(sequence, vocab):\n",
    "    \"\"\" Converts a sequence of indices back to text. \"\"\"\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}\n",
    "    return ' '.join(inv_vocab[idx] for idx in sequence if idx not in [vocab['<pad>'], vocab['<unk>']])\n",
    " \n",
    "# Decode sequence to text\n",
    "decoded_text = sequence_to_text(sequence, vocab)\n",
    "print(\"Decoded Text:\", decoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ca0435-db61-4a20-aa02-1bcfe1338ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 17.744062423706055\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    " \n",
    "# Simple RNN model for demonstration\n",
    "class SpeechModel(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size=128, num_layers=1):\n",
    "        super(SpeechModel, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=40, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs, _ = self.rnn(x)\n",
    "        outputs = self.fc(outputs)\n",
    "        return outputs\n",
    "\n",
    " \n",
    "# Initialize the model, loss, and optimizer\n",
    "model = SpeechModel(num_classes=len(char_list))\n",
    "ctc_loss = nn.CTCLoss(blank=char2idx['<blank>'], zero_infinity=True)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    " \n",
    "# Dummy data for demonstration (random tensors as inputs and targets)\n",
    "inputs = torch.rand(10, 100, 40)  # (batch_size, sequence_length, num_features)\n",
    "target_lengths = torch.full((10,), 15, dtype=torch.long)\n",
    "input_lengths = torch.full((10,), 100, dtype=torch.long)\n",
    "targets = torch.randint(1, len(char_list), (10, 15), dtype=torch.long)\n",
    " \n",
    "# Training step\n",
    "optimizer.zero_grad()\n",
    "outputs = model(inputs)  # Shape: (batch_size, sequence_length, num_classes)\n",
    "outputs = outputs.permute(1, 0, 2)  # Align output for CTC Loss: (sequence_length, batch_size, num_classes)\n",
    "loss = ctc_loss(outputs.log_softmax(2), targets, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    " \n",
    "print(\"Training loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e58f19-b10a-4329-9519-b85a861d5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c51ef-c493-44bd-996f-b037de3b9251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
